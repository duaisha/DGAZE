{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37255bd6-d73c-4d5d-9902-4b7fb771285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6ae614-0f37-40b5-8875-a115cfb98562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(image):\n",
    "    '''\n",
    "    function to detect face bounding box\n",
    "    '''\n",
    "    # initialize dlib's face detect or (HOG-based) and then  create\n",
    "    # the facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor.dat\")\n",
    "    \n",
    "    # load the input image, resize it, and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 1)\n",
    "    \n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "\n",
    "        # detect facial bounding box (x, y, w, h) using dlib library  \n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "        \n",
    "        return x,y,w,h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "acad8265-89b7-4131-97c2-c15fb65cfd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver19 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver2 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver21 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver23 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver8 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver20 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver13 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver16 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver11 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver17 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver22 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver24 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver10 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver14 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver5 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver15 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver12 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver7 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver18 ['drop_rate_per_video.csv', 'driver_view']\n",
      "driver3 ['drop_rate_per_video.csv', 'driver_view']\n"
     ]
    }
   ],
   "source": [
    "drivers = os.listdir('/ssd_scratch/cvit/isha_thrupthi/eye_gaze_mapping/DGAZE/dataset_download/')\n",
    "for driver in drivers:\n",
    "    if driver != 'road_view':\n",
    "        p = '/ssd_scratch/cvit/isha_thrupthi/eye_gaze_mapping/DGAZE/dataset_download/' + driver\n",
    "        print(driver, os.listdir(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45ebf8f-2a5e-4dfc-b9da-2a8c578e816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_frame_count(input_video):\n",
    "#     '''\n",
    "#     func to count number of frames in input video\n",
    "#     ''' \n",
    "#     count = 0\n",
    "#     vid = cv2.VideoCapture(input_video)\n",
    "#     while(True):\n",
    "#         ret, frame = vid.read()\n",
    "#         if(ret == False):\n",
    "#             break\n",
    "#         count += 1\n",
    "#     return count\n",
    "\n",
    "# def get_align_videos(path, driver, sample_no, driver_view_out, road_view_out):\n",
    "#     '''\n",
    "#     func to obtain road view by matching frames from driver view, \n",
    "#     road view and projected road view to get the same number of frames in each.\n",
    "#     steps:\n",
    "#         -- get number of frames in driver view, projected road view and actual road view\n",
    "#         -- Drop extra frames using (drop = larger_frame_count/diff) to get equal number of frames in each video\n",
    "#     '''\n",
    "#     driver_view = os.path.join(path, 'dataset_download', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')            \n",
    "#     projected_road_view = os.path.join(path, 'dataset_download', driver, 'projected_road_view', 'sample' + str(sample_no) +'.avi')  \n",
    "#     road_view = os.path.join(path,  'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out_hist.avi')\n",
    "              \n",
    "#     if sample_no < 10:\n",
    "#         gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.npy')\n",
    "#     else:\n",
    "#         gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.txt')\n",
    "      \n",
    "                                     \n",
    "#     cap_driver_view = cv2.VideoCapture(driver_view) # read driver view\n",
    "#     nframes_driver_view = get_frame_count(driver_view) # frame count of driver view video\n",
    "    \n",
    "#     cap_projected_road_view = cv2.VideoCapture(projected_road_view) # read projected_road view\n",
    "#     nframes_projected_road_view = get_frame_count(projected_road_view) # frame count of projected_road view video\n",
    "    \n",
    "#     cap_road_view = cv2.VideoCapture(road_view) # read road view\n",
    "#     nframes_road_view = get_frame_count(road_view) # frame count of road view video\n",
    "    \n",
    "#     if nframes_driver_view != nframes_projected_road_view:\n",
    "#         print(f'For {driver} and sample_no{sample_no} --> dview-{nframes_driver_view}, rview-{nframes_road_view}, prview-{nframes_projected_road_view}')     \n",
    "    \n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    \n",
    "#     driver_view_out = os.path.join(path, 'dataset', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')\n",
    "#     driver_view_out = cv2.VideoWriter(driver_view_out, fourcc, 25, (1440,1080)) \n",
    "    \n",
    "#     road_view_out = os.path.join(path,  'dataset', driver, 'road_view', 'sample' + str(sample_no) +'.avi')\n",
    "#     road_view_out = cv2.VideoWriter(road_view_out, fourcc, 25, (1920, 1080)) \n",
    "    \n",
    "#     road_gaze_point_out = os.path.join(path,  'dataset', driver, 'road_view', 'sample' + str(sample_no) +'.npy')\n",
    "    \n",
    "    \n",
    "#     flag =0; i = 0; count = 0; k = 0; gaze_point_out = []\n",
    "\n",
    "#     if(nframes_projected_road_view == nframes_road_view):\n",
    "#         flag = 1\n",
    "#         nframes = nframes_projected_road_view\n",
    "#         first = nframes_projected_road_view\n",
    "#         second = nframes_road_view\n",
    "\n",
    "#     elif(nframes_road_view < nframes_projected_road_view):\n",
    "#         nframes = nframes_projected_road_view \n",
    "#         first = nframes_projected_road_view \n",
    "#         second = nframes_road_view \n",
    "\n",
    "#     elif(nframes_road_view > nframes_projected_road_view):\n",
    "#         nframes = nframes_road_view\n",
    "#         first = nframes_road_view\n",
    "#         second = nframes_projected_road_view\n",
    "\n",
    "#     diff = first - second\n",
    "#     if(diff != 0):\n",
    "#         drop = np.round(first/diff)\n",
    "    \n",
    "#     while(i < nframes):\n",
    "#         i += 1             \n",
    "#         ret1, frame1 = cap_driver_view.read()\n",
    "#         if(diff != 0 and i%drop == 0):\n",
    "#             if(nframes_projected_road_view > nframes_road_view):\n",
    "#                 ret1, frame1 = cap_driver_view.read()\n",
    "#             else:\n",
    "#                 ret3, frame3 = cap_road_view.read()\n",
    "#                 k +=1\n",
    "#         else:\n",
    "#             ret1, frame1 = cap_driver_view.read()\n",
    "#             ret3, frame3 = cap_road_view.read()\n",
    "#             if(ret1 == False or ret3 == False):\n",
    "#                 break\n",
    "#             gaze_point_out.append(gt_point[k])\n",
    "#             k +=1\n",
    "            \n",
    "#             count += 1\n",
    "#             driver_view_out.write(frame1)\n",
    "#             road_view_out.write(frame3)\n",
    "            \n",
    "              \n",
    "#     print(\"check2\", first, second, count, np.array(gaze_point_out).shape)\n",
    "    \n",
    "#     gaze_point_out = np.array(gaze_point_out)\n",
    "#     np.save(road_gaze_point_out, gaze_point_out)\n",
    "        \n",
    "#     driver_view_out.release(); road_view_out.release();\n",
    "#     cap_driver_view.release(); cap_projected_road_view.release(); cap_road_view.release()\n",
    "             \n",
    "      \n",
    "        \n",
    "\n",
    "# from tqdm import tqdm                      \n",
    "# def align_videos(path):\n",
    "\n",
    "#     drivers = os.listdir(path + 'dataset_download/')\n",
    "    \n",
    "#     for driver in drivers:\n",
    "        \n",
    "#         nsamples = len(os.path.join(path, 'dataset_download', driver, 'driver_view'))\n",
    "        \n",
    "#         driver_view_out = os.path.join(path, 'dataset', driver, 'driver_view')\n",
    "#         if not os.path.exists(driver_view_out):\n",
    "#             os.makedirs(driver_view_out, exist_ok=True)\n",
    "\n",
    "#         road_view_out = os.path.join(path, 'dataset', driver, 'road_view')\n",
    "#         if not os.path.exists(road_view_out):\n",
    "#             os.makedirs(road_view_out, exist_ok=True)\n",
    "\n",
    "#         print(driver)\n",
    "#         for sample_no in tqdm(range(1, nsamples+1)):\n",
    "#             get_align_videos(path, driver, sample_no, driver_view_out, road_view_out)\n",
    "\n",
    "            \n",
    "# path = '/ssd_scratch/cvit/isha_thrupthi/eye_gaze_mapping/DGAZE/'\n",
    "# # align_videos(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "49430f1a-8caa-4e42-adea-3391528b8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_count(input_video):\n",
    "    '''\n",
    "    func to count number of frames in input video\n",
    "    ''' \n",
    "    count = 0\n",
    "    vid = cv2.VideoCapture(input_video)\n",
    "    while(True):\n",
    "        ret, frame = vid.read()\n",
    "        if(ret == False):\n",
    "            break\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def get_drop_rate(path, driver, sample_no):\n",
    "    '''\n",
    "    func to obtain road view by matching frames from driver view, \n",
    "    road view and projected road view to get the same number of frames in each.\n",
    "    steps:\n",
    "        -- get number of frames in driver view, projected road view and actual road view\n",
    "        -- Drop extra frames using (drop = larger_frame_count/diff) to get equal number of frames in each video\n",
    "    '''\n",
    "    driver_view = os.path.join(path, 'dataset_download', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')            \n",
    "    projected_road_view = os.path.join(path, 'dataset_download', driver, 'projected_road_view', 'sample' + str(sample_no) +'.avi')  \n",
    "    road_view = os.path.join(path,  'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out_hist.avi')\n",
    "              \n",
    "    if sample_no < 10:\n",
    "        gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.npy')\n",
    "    else:\n",
    "        gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.txt')\n",
    "      \n",
    "                                     \n",
    "    cap_driver_view = cv2.VideoCapture(driver_view) # read driver view\n",
    "    nframes_driver_view = get_frame_count(driver_view) # frame count of driver view video\n",
    "    \n",
    "    cap_projected_road_view = cv2.VideoCapture(projected_road_view) # read projected_road view\n",
    "    nframes_projected_road_view = get_frame_count(projected_road_view) # frame count of projected_road view video\n",
    "    \n",
    "    cap_road_view = cv2.VideoCapture(road_view) # read road view\n",
    "    nframes_road_view = get_frame_count(road_view) # frame count of road view video\n",
    "    \n",
    "    if nframes_driver_view != nframes_projected_road_view:\n",
    "        print(f'For {driver} and sample_no{sample_no} --> dview-{nframes_driver_view}, rview-{nframes_road_view}, prview-{nframes_projected_road_view}')     \n",
    " \n",
    "    flag =0; i = 0; count = 0; k = 0; gaze_point_out = []\n",
    "\n",
    "    if(nframes_projected_road_view == nframes_road_view):\n",
    "        flag = 1\n",
    "        nframes = nframes_projected_road_view\n",
    "        first = nframes_projected_road_view\n",
    "        second = nframes_road_view\n",
    "\n",
    "    elif(nframes_road_view < nframes_projected_road_view):\n",
    "        nframes = nframes_projected_road_view \n",
    "        first = nframes_projected_road_view \n",
    "        second = nframes_road_view \n",
    "\n",
    "    elif(nframes_road_view > nframes_projected_road_view):\n",
    "        nframes = nframes_road_view\n",
    "        first = nframes_road_view\n",
    "        second = nframes_projected_road_view\n",
    "\n",
    "    diff = first - second\n",
    "    if(diff != 0):\n",
    "        drop = np.round(first/diff)\n",
    "    else:\n",
    "        drop = -1\n",
    "    \n",
    "    return drop\n",
    "      \n",
    "        \n",
    "def drop_rate_per_sample(path):\n",
    "    drivers = os.listdir(path + 'dataset_download/')\n",
    "    \n",
    "    for driver in drivers:\n",
    "        \n",
    "        nsamples = len(os.listdir(os.path.join(path, 'dataset_download', driver, 'driver_view')))\n",
    "        \n",
    "        drop_rate_file = open(os.path.join(path, 'dataset_download', driver, 'drop_rate_per_video.csv'),\"w\")\n",
    "        drop_rate_file.write('sample_no' + ',' + 'drop_rate' +\"\\n\")\n",
    "        \n",
    "        print(driver)\n",
    "        for sample_no in tqdm(range(1, nsamples+1)):\n",
    "            drop = get_drop_rate(path, driver, sample_no)\n",
    "            drop_rate_file.write('sample'+str(sample_no)+'.avi' + ',' + str(drop)+\"\\n\")\n",
    "                \n",
    "        drop_rate_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d6b620d8-46cd-4479-9a87-be2b39507df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_align_videos(path, driver, sample_no, driver_view_out, road_view_out, drop):\n",
    "    '''\n",
    "    func to obtain road view by matching frames from driver view, \n",
    "    road view and projected road view to get the same number of frames in each.\n",
    "    steps:\n",
    "        -- get number of frames in driver view, projected road view and actual road view\n",
    "        -- Drop extra frames using (drop = larger_frame_count/diff) to get equal number of frames in each video\n",
    "    '''\n",
    "    driver_view = os.path.join(path, 'dataset_download', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')            \n",
    "    projected_road_view = os.path.join(path, 'dataset_download', driver, 'projected_road_view', 'sample' + str(sample_no) +'.avi')  \n",
    "    road_view = os.path.join(path,  'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out_hist.avi')\n",
    "              \n",
    "    if sample_no < 10:\n",
    "        gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.npy')\n",
    "        gt_point = np.load(gt_point)\n",
    "    else:\n",
    "        gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.txt')\n",
    "        gt_point = pd.read_csv(gt_point, header = None).values   \n",
    "                                     \n",
    "    cap_driver_view = cv2.VideoCapture(driver_view) # read driver view\n",
    "    nframes_driver_view = get_frame_count(driver_view) # frame count of driver view video\n",
    "    \n",
    "    cap_projected_road_view = cv2.VideoCapture(projected_road_view) # read projected_road view\n",
    "    nframes_projected_road_view = get_frame_count(projected_road_view) # frame count of projected_road view video\n",
    "    \n",
    "    cap_road_view = cv2.VideoCapture(road_view) # read road view\n",
    "    nframes_road_view = get_frame_count(road_view) # frame count of road view video\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    \n",
    "    driver_view_out = os.path.join(path, 'dataset', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')\n",
    "    driver_view_out = cv2.VideoWriter(driver_view_out, fourcc, 25, (1440,1080)) \n",
    "    \n",
    "    road_view_out = os.path.join(path,  'dataset', driver, 'road_view', 'sample' + str(sample_no) +'.avi')\n",
    "    road_view_out = cv2.VideoWriter(road_view_out, fourcc, 25, (1920, 1080)) \n",
    "    \n",
    "    road_gaze_point_out = os.path.join(path,  'dataset', driver, 'road_view', 'sample' + str(sample_no) +'.npy')\n",
    "    \n",
    "    i = 0; count = 0; k = 0; gaze_point_out = []\n",
    "\n",
    "    nframes = nframes_projected_road_view\n",
    "\n",
    "    while(i < nframes):\n",
    "        i += 1     \n",
    "        if(drop != -1 and i%drop == 0):\n",
    "            if(nframes_projected_road_view > nframes_road_view):\n",
    "                ret1, frame1 = cap_driver_view.read()\n",
    "            else:\n",
    "                ret3, frame3 = cap_road_view.read()\n",
    "                k +=1\n",
    "        else:\n",
    "            ret1, frame1 = cap_driver_view.read()\n",
    "            ret3, frame3 = cap_road_view.read()\n",
    "            if(ret1 == False or ret3 == False):\n",
    "                break\n",
    "            gaze_point_out.append(gt_point[k])\n",
    "            k +=1\n",
    "            \n",
    "            count += 1\n",
    "            driver_view_out.write(frame1)\n",
    "            road_view_out.write(frame3)\n",
    "            \n",
    "              \n",
    "    gaze_point_out = np.array(gaze_point_out)\n",
    "    np.save(road_gaze_point_out, gaze_point_out)\n",
    "        \n",
    "    driver_view_out.release(); road_view_out.release();\n",
    "    cap_driver_view.release(); cap_projected_road_view.release(); cap_road_view.release()\n",
    "             \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f9c7463-eeb4-4072-8526-b2c9c8939c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_videos(path):\n",
    "    drivers = os.listdir(path + 'dataset_download/')\n",
    "    \n",
    "    for driver in drivers:\n",
    "        nsamples = len(os.listdir(os.path.join(path, 'dataset_download', driver, 'driver_view')))\n",
    "        \n",
    "        driver_view_out = os.path.join(path, 'dataset', driver, 'driver_view')\n",
    "        if not os.path.exists(driver_view_out):\n",
    "            os.makedirs(driver_view_out, exist_ok=True)\n",
    "\n",
    "        road_view_out = os.path.join(path, 'dataset', driver, 'road_view')\n",
    "        if not os.path.exists(road_view_out):\n",
    "            os.makedirs(road_view_out, exist_ok=True)\n",
    "\n",
    "        drop_data = pd.read_csv(os.path.join(path, 'dataset_download', driver, 'drop_rate_per_video.csv'))\n",
    "        samples = drop_data['sample_no']\n",
    "        drop_rate = drop_data['drop_rate'].astype(int)\n",
    "\n",
    "        print(driver, nsamples)\n",
    "        for sample_no in tqdm(range(1, nsamples+1)):\n",
    "            drop = drop_rate[np.where(samples == 'sample'+str(sample_no)+'.avi')[0][0]]\n",
    "            get_align_videos(path, driver, sample_no, driver_view_out, road_view_out, drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9d273e7b-5e30-425c-a7f6-cfcc2cc249c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'align_videos' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-4a7b8cd33baf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/ssd_scratch/cvit/isha_thrupthi/eye_gaze_mapping/DGAZE/'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# drop_rate_per_sample(path)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0malign_videos\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'align_videos' is not defined"
     ]
    }
   ],
   "source": [
    "path = '/ssd_scratch/cvit/isha_thrupthi/eye_gaze_mapping/DGAZE/'\n",
    "# drop_rate_per_sample(path)\n",
    "align_videos(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f2ef61a-27e0-4787-b7f7-753df45be37a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Processing for driver19\n",
      "--> Processing for driver2\n",
      "--> Processing for driver21\n",
      "--> Processing for driver23\n",
      "--> Processing for driver8\n",
      "--> Processing for driver20\n",
      "--> Processing for driver13\n",
      "--> Processing for driver16\n",
      "--> Processing for driver11\n",
      "--> Processing for driver17\n",
      "--> Processing for driver22\n",
      "--> Processing for driver24\n",
      "--> Processing for driver10\n",
      "--> Processing for driver14\n",
      "--> Processing for driver5\n",
      "--> Processing for driver15\n",
      "--> Processing for driver12\n",
      "--> Processing for driver7\n",
      "100%|█████████████████████████████████████████| 112/112 [10:24<00:00,  5.57s/it]\n",
      "--> Processing for driver18\n",
      "100%|█████████████████████████████████████████| 112/112 [11:32<00:00,  6.18s/it]\n",
      "--> Processing for driver3\n",
      "100%|█████████████████████████████████████████| 112/112 [11:45<00:00,  6.30s/it]\n"
     ]
    }
   ],
   "source": [
    "!python dataset.py --path '/ssd_scratch/cvit/isha_thrupthi/eye_gaze_mapping/DGAZE/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcaf026-43fb-40ec-8ed5-d844e2918b33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2cb594a-e800-45ed-9bd3-ee81abaaa3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
