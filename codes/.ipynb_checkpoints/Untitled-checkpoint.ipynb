{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37255bd6-d73c-4d5d-9902-4b7fb771285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dlib\n",
    "from imutils import face_utils\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb6ae614-0f37-40b5-8875-a115cfb98562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bbox(image):\n",
    "    '''\n",
    "    function to detect face bounding box\n",
    "    '''\n",
    "    # initialize dlib's face detect or (HOG-based) and then  create\n",
    "    # the facial landmark predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(\"shape_predictor.dat\")\n",
    "    \n",
    "    # load the input image, resize it, and convert it to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces in the grayscale image\n",
    "    rects = detector(gray, 1)\n",
    "    \n",
    "    # loop over the face detections\n",
    "    for (i, rect) in enumerate(rects):\n",
    "\n",
    "        # detect facial bounding box (x, y, w, h) using dlib library  \n",
    "        (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "        \n",
    "        return x,y,w,h\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad8265-89b7-4131-97c2-c15fb65cfd6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b45ebf8f-2a5e-4dfc-b9da-2a8c578e816a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_frame_count(input_video):\n",
    "#     '''\n",
    "#     func to count number of frames in input video\n",
    "#     ''' \n",
    "#     count = 0\n",
    "#     vid = cv2.VideoCapture(input_video)\n",
    "#     while(True):\n",
    "#         ret, frame = vid.read()\n",
    "#         if(ret == False):\n",
    "#             break\n",
    "#         count += 1\n",
    "#     return count\n",
    "\n",
    "# def get_align_videos(path, driver, sample_no, driver_view_out, road_view_out):\n",
    "#     '''\n",
    "#     func to obtain road view by matching frames from driver view, \n",
    "#     road view and projected road view to get the same number of frames in each.\n",
    "#     steps:\n",
    "#         -- get number of frames in driver view, projected road view and actual road view\n",
    "#         -- Drop extra frames using (drop = larger_frame_count/diff) to get equal number of frames in each video\n",
    "#     '''\n",
    "#     driver_view = os.path.join(path, 'dataset_download', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')            \n",
    "#     projected_road_view = os.path.join(path, 'dataset_download', driver, 'projected_road_view', 'sample' + str(sample_no) +'.avi')  \n",
    "#     road_view = os.path.join(path,  'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out_hist.avi')\n",
    "              \n",
    "#     if sample_no < 10:\n",
    "#         gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.npy')\n",
    "#     else:\n",
    "#         gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.txt')\n",
    "      \n",
    "                                     \n",
    "#     cap_driver_view = cv2.VideoCapture(driver_view) # read driver view\n",
    "#     nframes_driver_view = get_frame_count(driver_view) # frame count of driver view video\n",
    "    \n",
    "#     cap_projected_road_view = cv2.VideoCapture(projected_road_view) # read projected_road view\n",
    "#     nframes_projected_road_view = get_frame_count(projected_road_view) # frame count of projected_road view video\n",
    "    \n",
    "#     cap_road_view = cv2.VideoCapture(road_view) # read road view\n",
    "#     nframes_road_view = get_frame_count(road_view) # frame count of road view video\n",
    "    \n",
    "#     if nframes_driver_view != nframes_projected_road_view:\n",
    "#         print(f'For {driver} and sample_no{sample_no} --> dview-{nframes_driver_view}, rview-{nframes_road_view}, prview-{nframes_projected_road_view}')     \n",
    "    \n",
    "#     fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    \n",
    "#     driver_view_out = os.path.join(path, 'dataset', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')\n",
    "#     driver_view_out = cv2.VideoWriter(driver_view_out, fourcc, 25, (1440,1080)) \n",
    "    \n",
    "#     road_view_out = os.path.join(path,  'dataset', driver, 'road_view', 'sample' + str(sample_no) +'.avi')\n",
    "#     road_view_out = cv2.VideoWriter(road_view_out, fourcc, 25, (1920, 1080)) \n",
    "    \n",
    "#     road_gaze_point_out = os.path.join(path,  'dataset', driver, 'road_view', 'sample' + str(sample_no) +'.npy')\n",
    "    \n",
    "    \n",
    "#     flag =0; i = 0; count = 0; k = 0; gaze_point_out = []\n",
    "\n",
    "#     if(nframes_projected_road_view == nframes_road_view):\n",
    "#         flag = 1\n",
    "#         nframes = nframes_projected_road_view\n",
    "#         first = nframes_projected_road_view\n",
    "#         second = nframes_road_view\n",
    "\n",
    "#     elif(nframes_road_view < nframes_projected_road_view):\n",
    "#         nframes = nframes_projected_road_view \n",
    "#         first = nframes_projected_road_view \n",
    "#         second = nframes_road_view \n",
    "\n",
    "#     elif(nframes_road_view > nframes_projected_road_view):\n",
    "#         nframes = nframes_road_view\n",
    "#         first = nframes_road_view\n",
    "#         second = nframes_projected_road_view\n",
    "\n",
    "#     diff = first - second\n",
    "#     if(diff != 0):\n",
    "#         drop = np.round(first/diff)\n",
    "    \n",
    "#     while(i < nframes):\n",
    "#         i += 1             \n",
    "#         ret1, frame1 = cap_driver_view.read()\n",
    "#         if(diff != 0 and i%drop == 0):\n",
    "#             if(nframes_projected_road_view > nframes_road_view):\n",
    "#                 ret1, frame1 = cap_driver_view.read()\n",
    "#             else:\n",
    "#                 ret3, frame3 = cap_road_view.read()\n",
    "#                 k +=1\n",
    "#         else:\n",
    "#             ret1, frame1 = cap_driver_view.read()\n",
    "#             ret3, frame3 = cap_road_view.read()\n",
    "#             if(ret1 == False or ret3 == False):\n",
    "#                 break\n",
    "#             gaze_point_out.append(gt_point[k])\n",
    "#             k +=1\n",
    "            \n",
    "#             count += 1\n",
    "#             driver_view_out.write(frame1)\n",
    "#             road_view_out.write(frame3)\n",
    "            \n",
    "              \n",
    "#     print(\"check2\", first, second, count, np.array(gaze_point_out).shape)\n",
    "    \n",
    "#     gaze_point_out = np.array(gaze_point_out)\n",
    "#     np.save(road_gaze_point_out, gaze_point_out)\n",
    "        \n",
    "#     driver_view_out.release(); road_view_out.release();\n",
    "#     cap_driver_view.release(); cap_projected_road_view.release(); cap_road_view.release()\n",
    "             \n",
    "      \n",
    "        \n",
    "\n",
    "# from tqdm import tqdm                      \n",
    "# def align_videos(path):\n",
    "\n",
    "#     drivers = os.listdir(path + 'dataset_download/')\n",
    "    \n",
    "#     for driver in drivers:\n",
    "        \n",
    "#         nsamples = len(os.path.join(path, 'dataset_download', driver, 'driver_view'))\n",
    "        \n",
    "#         driver_view_out = os.path.join(path, 'dataset', driver, 'driver_view')\n",
    "#         if not os.path.exists(driver_view_out):\n",
    "#             os.makedirs(driver_view_out, exist_ok=True)\n",
    "\n",
    "#         road_view_out = os.path.join(path, 'dataset', driver, 'road_view')\n",
    "#         if not os.path.exists(road_view_out):\n",
    "#             os.makedirs(road_view_out, exist_ok=True)\n",
    "\n",
    "#         print(driver)\n",
    "#         for sample_no in tqdm(range(1, nsamples+1)):\n",
    "#             get_align_videos(path, driver, sample_no, driver_view_out, road_view_out)\n",
    "\n",
    "            \n",
    "# path = '/ssd_scratch/cvit/isha_thrupthi/eye_gaze_mapping/DGAZE/'\n",
    "# # align_videos(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "49430f1a-8caa-4e42-adea-3391528b8824",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_count(input_video):\n",
    "    '''\n",
    "    func to count number of frames in input video\n",
    "    ''' \n",
    "    count = 0\n",
    "    vid = cv2.VideoCapture(input_video)\n",
    "    while(True):\n",
    "        ret, frame = vid.read()\n",
    "        if(ret == False):\n",
    "            break\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def get_drop_rate(path, driver, sample_no):\n",
    "    '''\n",
    "    func to obtain road view by matching frames from driver view, \n",
    "    road view and projected road view to get the same number of frames in each.\n",
    "    steps:\n",
    "        -- get number of frames in driver view, projected road view and actual road view\n",
    "        -- Drop extra frames using (drop = larger_frame_count/diff) to get equal number of frames in each video\n",
    "    '''\n",
    "    driver_view = os.path.join(path, 'dataset_download', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')            \n",
    "    projected_road_view = os.path.join(path, 'dataset_download', driver, 'projected_road_view', 'sample' + str(sample_no) +'.avi')  \n",
    "    road_view = os.path.join(path,  'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out_hist.avi')\n",
    "              \n",
    "    if sample_no < 10:\n",
    "        gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.npy')\n",
    "    else:\n",
    "        gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.txt')\n",
    "      \n",
    "                                     \n",
    "    cap_driver_view = cv2.VideoCapture(driver_view) # read driver view\n",
    "    nframes_driver_view = get_frame_count(driver_view) # frame count of driver view video\n",
    "    \n",
    "    cap_projected_road_view = cv2.VideoCapture(projected_road_view) # read projected_road view\n",
    "    nframes_projected_road_view = get_frame_count(projected_road_view) # frame count of projected_road view video\n",
    "    \n",
    "    cap_road_view = cv2.VideoCapture(road_view) # read road view\n",
    "    nframes_road_view = get_frame_count(road_view) # frame count of road view video\n",
    "    \n",
    "    if nframes_driver_view != nframes_projected_road_view:\n",
    "        print(f'For {driver} and sample_no{sample_no} --> dview-{nframes_driver_view}, rview-{nframes_road_view}, prview-{nframes_projected_road_view}')     \n",
    " \n",
    "    flag =0; i = 0; count = 0; k = 0; gaze_point_out = []\n",
    "\n",
    "    if(nframes_projected_road_view == nframes_road_view):\n",
    "        flag = 1\n",
    "        nframes = nframes_projected_road_view\n",
    "        first = nframes_projected_road_view\n",
    "        second = nframes_road_view\n",
    "\n",
    "    elif(nframes_road_view < nframes_projected_road_view):\n",
    "        nframes = nframes_projected_road_view \n",
    "        first = nframes_projected_road_view \n",
    "        second = nframes_road_view \n",
    "\n",
    "    elif(nframes_road_view > nframes_projected_road_view):\n",
    "        nframes = nframes_road_view\n",
    "        first = nframes_road_view\n",
    "        second = nframes_projected_road_view\n",
    "\n",
    "    diff = first - second\n",
    "    if(diff != 0):\n",
    "        drop = np.round(first/diff)\n",
    "    else:\n",
    "        drop = -1\n",
    "    \n",
    "    return drop\n",
    "      \n",
    "        \n",
    "def drop_rate_per_sample(path):\n",
    "    drivers = os.listdir(path + 'dataset_download/')\n",
    "    \n",
    "    for driver in drivers:\n",
    "        \n",
    "        nsamples = len(os.listdir(os.path.join(path, 'dataset_download', driver, 'driver_view')))\n",
    "        \n",
    "        drop_rate_file = open(os.path.join(path, 'dataset_download', driver, 'drop_rate_per_video.csv'),\"w\")\n",
    "        drop_rate_file.write('sample_no' + ',' + 'drop_rate' +\"\\n\")\n",
    "        \n",
    "        print(driver)\n",
    "        for sample_no in tqdm(range(1, nsamples+1)):\n",
    "            drop = get_drop_rate(path, driver, sample_no)\n",
    "            drop_rate_file.write('sample'+str(sample_no)+'.avi' + ',' + str(drop)+\"\\n\")\n",
    "                \n",
    "        drop_rate_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "d6b620d8-46cd-4479-9a87-be2b39507df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_align_videos(path, driver, sample_no, driver_view_out, road_view_out, drop):\n",
    "    '''\n",
    "    func to obtain road view by matching frames from driver view, \n",
    "    road view and projected road view to get the same number of frames in each.\n",
    "    steps:\n",
    "        -- get number of frames in driver view, projected road view and actual road view\n",
    "        -- Drop extra frames using (drop = larger_frame_count/diff) to get equal number of frames in each video\n",
    "    '''\n",
    "    driver_view = os.path.join(path, 'dataset_download', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')            \n",
    "    projected_road_view = os.path.join(path, 'dataset_download', driver, 'projected_road_view', 'sample' + str(sample_no) +'.avi')  \n",
    "    road_view = os.path.join(path,  'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out_hist.avi')\n",
    "              \n",
    "    if sample_no < 10:\n",
    "        gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.npy')\n",
    "        gt_point = np.load(gt_point)\n",
    "    else:\n",
    "        gt_point = os.path.join(path, 'dataset_download', 'road_view', 'trip' + str(sample_no) + '_out.txt')\n",
    "        gt_point = pd.read_csv(gt_point, header = None).values   \n",
    "                                     \n",
    "    cap_driver_view = cv2.VideoCapture(driver_view) # read driver view\n",
    "    nframes_driver_view = get_frame_count(driver_view) # frame count of driver view video\n",
    "    \n",
    "    cap_projected_road_view = cv2.VideoCapture(projected_road_view) # read projected_road view\n",
    "    nframes_projected_road_view = get_frame_count(projected_road_view) # frame count of projected_road view video\n",
    "    \n",
    "    cap_road_view = cv2.VideoCapture(road_view) # read road view\n",
    "    nframes_road_view = get_frame_count(road_view) # frame count of road view video\n",
    "    \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    \n",
    "    driver_view_out = os.path.join(path, 'dataset', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')\n",
    "    driver_view_out = cv2.VideoWriter(driver_view_out, fourcc, 25, (1440,1080)) \n",
    "    \n",
    "    road_view_out = os.path.join(path,  'dataset', driver, 'road_view', 'sample' + str(sample_no) +'.avi')\n",
    "    road_view_out = cv2.VideoWriter(road_view_out, fourcc, 25, (1920, 1080)) \n",
    "    \n",
    "    road_gaze_point_out = os.path.join(path,  'dataset', driver, 'road_view', 'sample' + str(sample_no) +'.npy')\n",
    "    \n",
    "    i = 0; count = 0; k = 0; gaze_point_out = []\n",
    "\n",
    "    nframes = nframes_projected_road_view\n",
    "\n",
    "    while(i < nframes):\n",
    "        i += 1     \n",
    "        if(drop != -1 and i%drop == 0):\n",
    "            if(nframes_projected_road_view > nframes_road_view):\n",
    "                ret1, frame1 = cap_driver_view.read()\n",
    "            else:\n",
    "                ret3, frame3 = cap_road_view.read()\n",
    "                k +=1\n",
    "        else:\n",
    "            ret1, frame1 = cap_driver_view.read()\n",
    "            ret3, frame3 = cap_road_view.read()\n",
    "            if(ret1 == False or ret3 == False):\n",
    "                break\n",
    "            gaze_point_out.append(gt_point[k])\n",
    "            k +=1\n",
    "            \n",
    "            count += 1\n",
    "            driver_view_out.write(frame1)\n",
    "            road_view_out.write(frame3)\n",
    "            \n",
    "              \n",
    "    gaze_point_out = np.array(gaze_point_out)\n",
    "    np.save(road_gaze_point_out, gaze_point_out)\n",
    "        \n",
    "    driver_view_out.release(); road_view_out.release();\n",
    "    cap_driver_view.release(); cap_projected_road_view.release(); cap_road_view.release()\n",
    "             \n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "1f9c7463-eeb4-4072-8526-b2c9c8939c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_videos(path):\n",
    "    drivers = os.listdir(path + 'dataset_download/')\n",
    "    \n",
    "    for driver in drivers:\n",
    "        nsamples = len(os.listdir(os.path.join(path, 'dataset_download', driver, 'driver_view')))\n",
    "        \n",
    "        driver_view_out = os.path.join(path, 'dataset', driver, 'driver_view')\n",
    "        if not os.path.exists(driver_view_out):\n",
    "            os.makedirs(driver_view_out, exist_ok=True)\n",
    "\n",
    "        road_view_out = os.path.join(path, 'dataset', driver, 'road_view')\n",
    "        if not os.path.exists(road_view_out):\n",
    "            os.makedirs(road_view_out, exist_ok=True)\n",
    "\n",
    "        drop_data = pd.read_csv(os.path.join(path, 'dataset_download', driver, 'drop_rate_per_video.csv'))\n",
    "        samples = drop_data['sample_no']\n",
    "        drop_rate = drop_data['drop_rate'].astype(int)\n",
    "\n",
    "        print(driver, nsamples)\n",
    "        for sample_no in tqdm(range(1, nsamples+1)):\n",
    "            drop = drop_rate[np.where(samples == 'sample'+str(sample_no)+'.avi')[0][0]]\n",
    "            get_align_videos(path, driver, sample_no, driver_view_out, road_view_out, drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9d273e7b-5e30-425c-a7f6-cfcc2cc249c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "driver5 112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 112/112 [11:35<00:00,  6.21s/it]\n"
     ]
    }
   ],
   "source": [
    "path = '/ssd_scratch/cvit/isha_thrupthi/eye_gaze_mapping/DGAZE/'\n",
    "# drop_rate_per_sample(path)\n",
    "align_videos(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2ef61a-27e0-4787-b7f7-753df45be37a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ffa960-75ad-4332-93cc-70ae1b5a8f87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3a36f81-1118-4d6c-a2ed-55b67d56a8df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import argparse\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f5dbd0d-1d4d-43e1-94d8-ac0421e0947f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/112 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--> Processing for driver5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = '/ssd_scratch/cvit/isha_thrupthi/eye_gaze_mapping/DGAZE/'\n",
    "dataset = os.path.join(path, 'dataset')\n",
    "drivers = os.listdir(dataset)\n",
    "for driver in drivers:\n",
    "    \n",
    "    print(f'--> Processing for {driver}')\n",
    "    \n",
    "    nsamples = len(os.listdir(os.path.join(path, 'dataset', driver, 'driver_view')))\n",
    "        \n",
    "    for sample_no in tqdm(range(1, nsamples+1)):\n",
    "        driver_view = os.path.join(path, 'dataset', driver, 'driver_view', 'sample' + str(sample_no) +'.avi')            \n",
    "        road_view = os.path.join(path,  'dataset', driver, 'road_view', 'sample' + str(sample_no) +'.avi')\n",
    "        gaze_point_path = os.path.join(path,  'dataset', driver, 'road_view', 'sample' + str(sample_no) +'.npy')\n",
    "        gt_point = np.load(gaze_point_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f8b22-b86a-4476-b0c6-f74bda33a640",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize(path):\n",
    "    drivers = os.listdir(path + 'dataset_download/')\n",
    "    \n",
    "    for driver in drivers:\n",
    "        nsamples = len(os.listdir(os.path.join(path, 'dataset_download', driver, 'driver_view')))\n",
    "        \n",
    "        driver_view_out = os.path.join(path, 'dataset', driver, 'driver_view')\n",
    "        if not os.path.exists(driver_view_out):\n",
    "            os.makedirs(driver_view_out, exist_ok=True)\n",
    "\n",
    "        road_view_out = os.path.join(path, 'dataset', driver, 'road_view')\n",
    "        if not os.path.exists(road_view_out):\n",
    "            os.makedirs(road_view_out, exist_ok=True)\n",
    "\n",
    "        drop_data = pd.read_csv(os.path.join(path, 'dataset_download', driver, 'drop_rate_per_video.csv'))\n",
    "        samples = drop_data['sample_no']\n",
    "        drop_rate = drop_data['drop_rate'].astype(int)\n",
    "\n",
    "        print(driver, nsamples)\n",
    "        for sample_no in tqdm(range(1, nsamples+1)):\n",
    "            drop = drop_rate[np.where(samples == 'sample'+str(sample_no)+'.avi')[0][0]]\n",
    "            get_align_videos(path, driver, sample_no, driver_view_out, road_view_out, drop)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
