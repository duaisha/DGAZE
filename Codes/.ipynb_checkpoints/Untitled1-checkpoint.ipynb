{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pfs/rdi/cei/algo_train/ishadua/SyntheticDataset/envs/a100/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import h5py\n",
    "import math\n",
    "import cv2\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "from torchvision import transforms as T\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda:0')\n",
    "torch.manual_seed(17)\n",
    "\n",
    "import math\n",
    "import copy\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGazeDataset(Dataset):\n",
    "    def __init__(self, driver_data, drivers, sequences, transform = False):\n",
    "        self.driver_data = driver_data\n",
    "        self.drivers = drivers\n",
    "        self.sequences = sequences\n",
    "        self.left_eye =  np.empty((0, 36, 60, 3))\n",
    "        self.facial_features = np.empty((0, 14))\n",
    "        self.gaze_point = np.empty((0, 2))\n",
    "#         print(sequences)\n",
    "        \n",
    "        for ix, driver in enumerate(drivers):\n",
    "            print(\"==>\", driver)\n",
    "            data = driver_data[driver]\n",
    "            for seq in tqdm(sequences):\n",
    "                if 'seq' + str(seq) in data.keys():\n",
    "                    data_seq = data['seq' + str(seq)]\n",
    "                    self.left_eye = np.concatenate((self.left_eye, data_seq['left_eye']), axis=0)\n",
    "                    seq_facial_features = np.concatenate((data_seq['headpose_pupil'][:,1:], data_seq['face_location']), axis=-1)\n",
    "                    self.facial_features = np.concatenate((self.facial_features, seq_facial_features), axis=0)\n",
    "                    self.gaze_point = np.concatenate((self.gaze_point, data_seq['gaze_point'][:,:2]), axis=0)\n",
    "\n",
    "        print(\"Data loaded!\")\n",
    "        self.normalize_eye_image()\n",
    "        self.normalize_facial_features() \n",
    "        self.fix_gaze_point()\n",
    "        self.gaze_point[:,0][self.gaze_point[:,0]<0] = 0\n",
    "        self.gaze_point[:,1][self.gaze_point[:,1]<0] = 0\n",
    "        self.index = np.arange(len(self.gaze_point))\n",
    "        \n",
    "        \n",
    "    def fix_gaze_point(self):\n",
    "        self.gaze_point[:,1][self.gaze_point[:,1]>=1080]=1080-1\n",
    "        self.gaze_point[:,0][self.gaze_point[:,0]>=1920]=1920-1\n",
    "\n",
    "\n",
    "    def normalize_eye_image(self):\n",
    "        # Calculate mean and standard deviation per channel\n",
    "        mean = self.left_eye.mean(axis=(0, 1, 2), keepdims=True)\n",
    "        std = self.left_eye.std(axis=(0, 1, 2), keepdims=True)\n",
    "\n",
    "#         print(\"\\nMean before normalization:\", self.left_eye.mean(axis=(0, 1, 2)))\n",
    "#         print(\"Standard deviation before normalization:\", self.left_eye.std(axis=(0, 1, 2)))\n",
    "        \n",
    "        # Normalize using mean and standard deviation\n",
    "        self.left_eye = (self.left_eye - mean) / std\n",
    "\n",
    "#         # Check the result\n",
    "#         print(\"\\nMean after normalization:\", self.left_eye.mean(axis=(0, 1, 2)))\n",
    "#         print(\"Standard deviation after normalization:\", self.left_eye.std(axis=(0, 1, 2)))\n",
    "        \n",
    "    def normalize_facial_features(self):\n",
    "        # Column-wise mean and standard deviation\n",
    "        mean = self.facial_features.mean(axis=0)\n",
    "        std = self.facial_features.std(axis=0)\n",
    "        \n",
    "#         # Verify that each column now has mean 0 and variance 1\n",
    "#         print(\"\\nMean of each column before normalization:\", self.facial_features.mean(axis=0))\n",
    "#         print(\"Variance of each column beforeafter normalization:\", self.facial_features.var(axis=0))\n",
    "\n",
    "        # Mean-variance normalization (standardization)\n",
    "        self.facial_features = (self.facial_features - mean) / std\n",
    "\n",
    "#         # Verify that each column now has mean 0 and variance 1\n",
    "#         print(\"\\nMean of each column after normalization:\", self.facial_features.mean(axis=0))\n",
    "#         print(\"Variance of each column after normalization:\", self.facial_features.var(axis=0))\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.index)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        index = self.index[idx]\n",
    "        left_eye = self.left_eye[index]\n",
    "        left_eye = np.transpose(left_eye, (2,0,1))\n",
    "        left_eye = torch.tensor(left_eye, dtype=torch.float32, device=device)\n",
    "        facial_features = torch.tensor(self.facial_features[index], dtype=torch.float32, device=device)\n",
    "        gaze_point = torch.tensor(self.gaze_point[index], dtype=torch.float32, device=device)\n",
    "        return  left_eye, facial_features, gaze_point\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IDGAZE(\n",
      "  (left_eye): LeftEyeModel(\n",
      "    (conv1): Conv2d(3, 20, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (dropout): Dropout(p=0.5, inplace=False)\n",
      "    (conv2): Conv2d(20, 50, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (face_features): FaceFeaturesModel(\n",
      "    (fc1): Linear(in_features=14, out_features=16, bias=True)\n",
      "  )\n",
      "  (fc2): Linear(in_features=4566, out_features=512, bias=True)\n",
      "  (fc3): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import init\n",
    "\n",
    "# Define the Left Eye Convolutional Model\n",
    "class LeftEyeModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeftEyeModel, self).__init__()\n",
    "        # First Conv layer\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=20, kernel_size=3)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "        # Second Conv layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=20, out_channels=50, kernel_size=3)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = self.dropout(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = torch.flatten(x, 1)  # Flatten the tensor for the next layer\n",
    "        return x\n",
    "\n",
    "# Define the Face Feature Dense Model\n",
    "class FaceFeaturesModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FaceFeaturesModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(14, 16)  # Equivalent to Dense(16, activation='relu', input_dim=14)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return x\n",
    "\n",
    "# Define the Merged Model\n",
    "class IDGAZE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IDGAZE, self).__init__()\n",
    "        self.left_eye = LeftEyeModel()\n",
    "        self.face_features = FaceFeaturesModel()\n",
    "        \n",
    "        # Dense Layers after Concatenation\n",
    "        self.fc2 = nn.Linear(4566, 512)  # Adjust 50*7*7 based on left_eye output dimensions\n",
    "        self.fc3 = nn.Linear(512, 2)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.left_eye(x1)\n",
    "        x2 = self.face_features(x2)\n",
    "        \n",
    "        # Concatenate outputs from the two models\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        \n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model and print the summary\n",
    "model = IDGAZE()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test(model, testdataset, batch_size=64):\n",
    "#     criterion = nn.L1Loss(reduction='sum')\n",
    "#     loader = DataLoader(testdataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "#     loss = 0\n",
    "#     numsamples = 0\n",
    "#     with torch.no_grad():\n",
    "#         for ii, (leye, x, gt) in enumerate(loader):\n",
    "#             out = model(leye.to(device), x.to(device))\n",
    "#             loss = loss + criterion(out, gt.to(device)).item()\n",
    "#             numsamples +=len(gt)\n",
    "\n",
    "#             print(f'Done {numsamples} of {len(testdataset)}              ', end='\\r')\n",
    "\n",
    "#     print('loss is ', loss/numsamples)\n",
    "\n",
    "\n",
    "# def train(model, traindataset, testdataset, batch_size=32):\n",
    "#     criterion = nn.L1Loss(reduction='sum')\n",
    "#     optimizer = optim.Adam(model.parameters(), lr=1e-7)\n",
    "#     loader = DataLoader(traindataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "#     for epoch in range(nepochs):\n",
    "#         running_loss=0\n",
    "#         numsamples=0\n",
    "#         for ii, (leye, feature, gt) in enumerate(loader):\n",
    "#             out = model(leye.to(device), feature.to(device))\n",
    "#             numsamples += gt.shape[0]\n",
    "#             optimizer.zero_grad()\n",
    "#             loss  = criterion(out, gt.to(device))\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             running_loss+=loss.item()\n",
    "#             if (ii+1)%10 == 0:\n",
    "#                 print(f'batch {ii} loss: {running_loss/numsamples:.4f}                    ', end = '\\r', flush=True)\n",
    "#                 running_loss=0\n",
    "#                 numsamples = 0\n",
    "\n",
    "#         print(f'Epoch {epoch} \\n\\ttrain error ', end=' ')\n",
    "#         test(model, traindataset)\n",
    "#         print('\\n\\ttest error: ', end= ' ')\n",
    "#         test(model, testdataset)\n",
    "#         torch.save(model.state_dict(), f'708_Model_epoch_{epoch:d}.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to log messages to both the console and a file\n",
    "def log_message(message, logfile='training_log.txt'):\n",
    "    print(message)\n",
    "    with open(logfile, 'a') as f:\n",
    "        f.write(message + '\\n')\n",
    "\n",
    "# Testing function\n",
    "def test(model, testdataset, batch_size=64, logfile='training_log.txt'):\n",
    "    criterion = nn.L1Loss(reduction='mean')\n",
    "    loader = DataLoader(testdataset, batch_size=batch_size, shuffle=False, num_workers=0)\n",
    "    loss = 0\n",
    "    numsamples = 0\n",
    "    with torch.no_grad():\n",
    "        for ii, (leye, x, gt) in enumerate(loader):\n",
    "            out = model(leye.to(device), x.to(device))\n",
    "            batch_loss = criterion(out, gt.to(device)).item()\n",
    "            loss += batch_loss\n",
    "            numsamples += len(gt)\n",
    "            \n",
    "#             log_message(f'Testing: Processed {numsamples}/{len(testdataset)} samples', logfile)\n",
    "\n",
    "#     avg_loss = loss / numsamples\n",
    "    avg_loss = loss\n",
    "    log_message(f'Testing completed. Average loss: {avg_loss:.4f}\\n', logfile)\n",
    "    return avg_loss\n",
    "\n",
    "# Training function\n",
    "def train(model, traindataset, testdataset, batch_size=32, nepochs=10, dump_path=None, logfile='training_log.txt'):\n",
    "    criterion = nn.L1Loss(reduction='mean')\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    train_loader = DataLoader(traindataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    logfile = os.path.join(dump_path, logfile)\n",
    "    log_message('Training started\\n', logfile)\n",
    "\n",
    "    for epoch in range(nepochs):\n",
    "        running_loss = 0\n",
    "        numsamples = 0\n",
    "        log_message(f'Starting Epoch {epoch + 1}/{nepochs}', logfile)\n",
    "\n",
    "        # Training loop\n",
    "        for ii, (leye, feature, gt) in enumerate(train_loader):\n",
    "            out = model(leye.to(device), feature.to(device))\n",
    "            loss = criterion(out, gt.to(device))\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Update tracking metrics\n",
    "            batch_loss = loss.item()\n",
    "            running_loss += batch_loss\n",
    "            numsamples += gt.shape[0]\n",
    "\n",
    "            if (ii + 1) % 10 == 0:\n",
    "                avg_batch_loss = running_loss \n",
    "#                 avg_batch_loss = running_loss / numsamples\n",
    "#                 log_message(f'Epoch [{epoch + 1}/{nepochs}], Batch [{ii + 1}/{len(train_loader)}], '\n",
    "#                             f'Average Loss: {avg_batch_loss:.4f}', logfile)\n",
    "                running_loss = 0\n",
    "                numsamples = 0\n",
    "\n",
    "        # Epoch summary\n",
    "        log_message(f'Completed Epoch {epoch + 1}/{nepochs}', logfile)\n",
    "        train_error = test(model, traindataset, batch_size, logfile)\n",
    "        test_error = test(model, testdataset, batch_size, logfile)\n",
    "        log_message(f'\\tTrain Error: {train_error:.4f}\\n\\tTest Error: {test_error:.4f}\\n', logfile)\n",
    "\n",
    "        # Save model after each epoch\n",
    "        torch.save(model.state_dict(), f'Model_epoch_{epoch + 1}.pth')\n",
    "        log_message(f'Model saved after Epoch {epoch + 1}\\n', logfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if __name__ =='__main__':\n",
    "# \tdevice = int(sys.argv[1])\n",
    "# \tif device==-1:\n",
    "# \t\tdevice = torch.device('cpu')\n",
    "# \telse:\n",
    "# \t\tdevice = torch.device(f'cuda:{device}')\n",
    "\n",
    "\n",
    "## Path\n",
    "DGAZE_extracted_data = '/pfs01/performance-tier/rd_algo/algo_bin/ishadua/codes/old_codes/DGAZE/DGAZE_extracted_data/DGAZE_extracted_data.pkl'\n",
    "DGAZE_data_split = '/pfs01/performance-tier/rd_algo/algo_bin/ishadua/codes/old_codes/DGAZE/DGAZE_extracted_data/DGAZE_data_split.pkl'\n",
    "dump_path = '/pfs01/performance-tier/rd_algo/algo_bin/ishadua/codes/old_codes/DGAZE/results/save_models/run1/'\n",
    "\n",
    "## Training Params\n",
    "batch_size = 32\n",
    "learning_rate = 0.001\n",
    "nepochs = 300\n",
    "\n",
    "# Load dictionary\n",
    "with open(DGAZE_extracted_data, 'rb') as file:\n",
    "    driver_data = pickle.load(file)\n",
    "    \n",
    "# Load dictionary\n",
    "with open(DGAZE_data_split, 'rb') as file:\n",
    "    data_split = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> driver22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 72/72 [00:03<00:00, 18.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> driver8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 72/72 [00:12<00:00,  5.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "==> driver16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 69.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> driver5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 26.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "==> driver14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 66.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> driver3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 15/15 [00:00<00:00, 22.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded!\n",
      "15770 3399 3719\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DGazeDataset(driver_data, data_split['drivers_train'][:2], data_split['sequence_train'])\n",
    "val_dataset = DGazeDataset(driver_data, data_split['drivers_val'][:2], data_split['sequence_val'])\n",
    "test_dataset = DGazeDataset(driver_data, data_split['drivers_test'][:2], data_split['sequence_test'])\n",
    "\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n",
      "\n",
      "Starting Epoch 1/10\n",
      "Completed Epoch 1/10\n",
      "Testing completed. Average loss: 87780.5622\n",
      "\n",
      "Testing completed. Average loss: 31048.7240\n",
      "\n",
      "\tTrain Error: 87780.5622\n",
      "\tTest Error: 31048.7240\n",
      "\n",
      "Model saved after Epoch 1\n",
      "\n",
      "Starting Epoch 2/10\n",
      "Completed Epoch 2/10\n"
     ]
    }
   ],
   "source": [
    "model = IDGAZE().to(device)\n",
    "train(model, train_dataset, val_dataset, dump_path=dump_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.gaze_point[:,:].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1920, 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a100",
   "language": "python",
   "name": "a100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
