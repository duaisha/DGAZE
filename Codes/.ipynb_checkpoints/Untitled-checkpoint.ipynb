{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# from load_dataset import get_data, dataset\n",
    "# from utils import print_metadata, get_dgaze_frames_count, split_data, plot_gaze_points, save_model, load_model\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# from sklearn.metrics import mean_absolute_error\n",
    "# import matplotlib.pyplot as plt\n",
    "# from tqdm import tqdm\n",
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import copy\n",
    "# import cv2 \n",
    "\n",
    "# from numpy.random import seed\n",
    "# seed(1)\n",
    "\n",
    "# from tensorflow import set_random_seed\n",
    "# set_random_seed(2)\n",
    "\n",
    "# import random \n",
    "# random.seed(3)\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n",
      "File \u001b[0;32m/pfs/rdi/cei/algo_train/ishadua/SyntheticDataset/envs/a100/lib/python3.10/site-packages/pandas/__init__.py:22\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m _hard_dependencies, _dependency, _missing_dependencies\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# numpy compat\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_numpy_dev \u001b[38;5;28;01mas\u001b[39;00m _is_numpy_dev  \u001b[38;5;66;03m# pyright: ignore # noqa:F401\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m hashtable \u001b[38;5;28;01mas\u001b[39;00m _hashtable, lib \u001b[38;5;28;01mas\u001b[39;00m _lib, tslib \u001b[38;5;28;01mas\u001b[39;00m _tslib\n",
      "File \u001b[0;32m/pfs/rdi/cei/algo_train/ishadua/SyntheticDataset/envs/a100/lib/python3.10/site-packages/pandas/compat/__init__.py:18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m F\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     19\u001b[0m     is_numpy_dev,\n\u001b[1;32m     20\u001b[0m     np_version_under1p21,\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcompat\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyarrow\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     23\u001b[0m     pa_version_under1p01,\n\u001b[1;32m     24\u001b[0m     pa_version_under2p0,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     31\u001b[0m     pa_version_under9p0,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n",
      "File \u001b[0;32m/pfs/rdi/cei/algo_train/ishadua/SyntheticDataset/envs/a100/lib/python3.10/site-packages/pandas/compat/numpy/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\" support numpy compatibility across versions \"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Version\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# numpy versioning\u001b[39;00m\n\u001b[1;32m      7\u001b[0m _np_version \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39m__version__\n",
      "File \u001b[0;32m/pfs/rdi/cei/algo_train/ishadua/SyntheticDataset/envs/a100/lib/python3.10/site-packages/pandas/util/__init__.py:2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# pyright: reportUnusedImport = false\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_decorators\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      3\u001b[0m     Appender,\n\u001b[1;32m      4\u001b[0m     Substitution,\n\u001b[1;32m      5\u001b[0m     cache_readonly,\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhashing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (  \u001b[38;5;66;03m# noqa:F401\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     hash_array,\n\u001b[1;32m     10\u001b[0m     hash_pandas_object,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getattr__\u001b[39m(name):\n",
      "File \u001b[0;32m/pfs/rdi/cei/algo_train/ishadua/SyntheticDataset/envs/a100/lib/python3.10/site-packages/pandas/util/_decorators.py:14\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     Any,\n\u001b[1;32m      8\u001b[0m     Callable,\n\u001b[1;32m      9\u001b[0m     Mapping,\n\u001b[1;32m     10\u001b[0m     cast,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mproperties\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cache_readonly\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_typing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     16\u001b[0m     F,\n\u001b[1;32m     17\u001b[0m     T,\n\u001b[1;32m     18\u001b[0m )\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_exceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m find_stack_level\n",
      "File \u001b[0;32m/pfs/rdi/cei/algo_train/ishadua/SyntheticDataset/envs/a100/lib/python3.10/site-packages/pandas/_libs/__init__.py:13\u001b[0m\n\u001b[1;32m      1\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaT\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNaTType\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterval\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     10\u001b[0m ]\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01minterval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_libs\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtslibs\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     15\u001b[0m     NaT,\n\u001b[1;32m     16\u001b[0m     NaTType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     iNaT,\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m/pfs/rdi/cei/algo_train/ishadua/SyntheticDataset/envs/a100/lib/python3.10/site-packages/pandas/_libs/interval.pyx:1\u001b[0m, in \u001b[0;36minit pandas._libs.interval\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def get_gaze_point(driver, seq, object_annot):\n",
    "    if seq < 9:\n",
    "        temp = np.ones((object_annot.shape[0],4))*-1\n",
    "        return np.hstack((object_annot,temp))\n",
    "    else:\n",
    "        bbox = object_annot\n",
    "        pt1 = (bbox[:,3] + bbox[:,1])/2\n",
    "        pt2 = (bbox[:,4] + bbox[:,2])/2\n",
    "        pt1 = np.expand_dims(pt1, axis =1)\n",
    "        pt2 = np.expand_dims(pt2, axis =1)\n",
    "        return np.hstack((pt1.astype(int), pt2.astype(int), object_annot[:,1:]))\n",
    "    \n",
    "    \n",
    "def modify_pupil(pupil, face_location):\n",
    "    \n",
    "    top_left_x = face_location[:,2:3] \n",
    "    top_left_y = face_location[:,0:1]\n",
    "    pupil[:, [4,6,9]] = pupil[:,[4,6,9]] + top_left_x\n",
    "    pupil[:, [5,7,10]] = pupil[:,[5,7,10]] + top_left_y\n",
    "    \n",
    "    return pupil\n",
    "\n",
    "def get_driver_features(data_path, driver, sequences, frames_per_seq = None):\n",
    "    \"\"\"\n",
    "    Load driver features for DGAZE:\n",
    "    Input: Images\n",
    "    Output: left_eye features of dim = (nframesx36x60x3)\n",
    "            right_eye features of dim = (nframesx36x60x3)\n",
    "            # We use face location in driver's input frame for calibration\n",
    "            face location features of dim = (nframesx4) \n",
    "            # face location means driver face location inside cars\n",
    "            headpose_pupil is of dim = (nframes x 11)\n",
    "            # (nframes, roll, pitch, yaw, lpupil(x,y), rpupil(x,y), face_area, nose(x,y))\n",
    "            # x,y left eye pupil location\n",
    "            gaze_point is ground truth of dim  = (nframesx6)\n",
    "            # First two values are x,y for point annotation(center of object)\n",
    "            # Next four are x,y corresponding to top left point of the object and bottom right of the object respectively.\n",
    "    \"\"\"\n",
    "\n",
    "    driver_features = {}\n",
    "    total_frames = 0\n",
    "    \n",
    "    driver_features_path = data_path + '/' + driver\n",
    "    eye_features_path = driver_features_path + \"/explicit_face_features_game/\"\n",
    "    face_features_path = driver_features_path + \"/explicit_face_points/\"\n",
    "    annot_path = driver_features_path +\"/original_road_view/\" \n",
    "    \n",
    "    if os.path.exists(eye_features_path) and os.path.exists(face_features_path) and os.path.exists(annot_path):\n",
    "        for seq in range(0, sequences):\n",
    "            features = {}\n",
    "\n",
    "            eye_features = eye_features_path + \"sample\" + str(seq+1)\n",
    "            face_location_features = face_features_path + \"sample_\" + str(seq+1)\n",
    "            annot = annot_path + \"sample_\" + str(seq+1) + \".npy\"\n",
    "\n",
    "            left_eye_features = eye_features + \"_left_eye_data.npy\"\n",
    "            right_eye_features = eye_features + \"_right_eye_data.npy\"\n",
    "            headpose_pupil_features = eye_features + \"_headpose_pupil.npy\"\n",
    "            face_location_features = face_location_features +\"_face_points.npy\"\n",
    "\n",
    "            if os.path.exists(left_eye_features) and os.path.exists(right_eye_features) and \\\n",
    "            os.path.exists(headpose_pupil_features) and os.path.exists(face_location_features):\n",
    "\n",
    "                if np.load(left_eye_features).shape[0] == get_gaze_point(driver, seq, np.load(annot)).shape[0]:\n",
    "\n",
    "                    features['left_eye']  = np.load(left_eye_features)\n",
    "                    features['right_eye'] = np.load(right_eye_features)\n",
    "                    features['headpose_pupil']  = np.load(headpose_pupil_features)\n",
    "                    features['face_location'] = np.load(face_location_features)\n",
    "                    features['headpose_pupil'] = modify_pupil(features['headpose_pupil'], features['face_location'])\n",
    "                    features['gaze_point'] = get_gaze_point(driver, seq, np.load(annot))\n",
    "                    total_frames += features['gaze_point'].shape[0]\n",
    "\n",
    "                    driver_features[\"\".join(['seq',str(seq+1)])] = features\n",
    "                    driver_features['frames_count'] = total_frames\n",
    "                else:\n",
    "#                     print(driver, seq+1, np.load(left_eye_features).shape[0], np.load(right_eye_features).shape[0],\\\n",
    "#                           np.load(annot).shape[0], get_gaze_point(driver, seq, np.load(annot)).shape[0])\n",
    "                    pass\n",
    "                \n",
    "    return driver_features\n",
    "\n",
    "\n",
    "def get_data(data_path, drivers, sequences, frames_per_seq = None):\n",
    "    data = {}\n",
    "    for driver in tqdm(drivers):\n",
    "        data[driver] = get_driver_features(data_path, driver, sequences)\n",
    "    return data\n",
    "\n",
    "\n",
    "def load_data(driver_data, driver, sequences, nframes = None):\n",
    "    gaze_point = None\n",
    "    left_eye = None\n",
    "    right_eye = None\n",
    "    headpose_pupil = None\n",
    "    face_location = None\n",
    "    \n",
    "   \n",
    "    for ix in tqdm((sequences), position=0, leave=True):\n",
    "        seq = \"\".join(['seq',str(ix)]) \n",
    "        if seq in driver_data[driver]:\n",
    "            data = driver_data[driver][\"\".join(['seq',str(ix)])]\n",
    "\n",
    "            if gaze_point is None:\n",
    "                gaze_point = data['gaze_point'][:nframes] if nframes != None else data['gaze_point']\n",
    "                left_eye = data['left_eye'][:nframes] if nframes != None else data['left_eye']\n",
    "                right_eye = data['right_eye'][:nframes] if nframes != None else data['right_eye']\n",
    "                headpose_pupil = data['headpose_pupil'][:nframes] if nframes != None else data['headpose_pupil']\n",
    "                face_location = data['face_location'][:nframes] if nframes != None else data['face_location']\n",
    "            else:\n",
    "                gaze_point = np.concatenate((gaze_point, data['gaze_point'][:nframes]),axis=0)\\\n",
    "                            if nframes != None else np.concatenate((gaze_point, data['gaze_point']),axis=0)\n",
    "                \n",
    "                left_eye = np.concatenate((left_eye, data['left_eye'][:nframes]),axis=0)\\\n",
    "                            if nframes != None else np.concatenate((left_eye, data['left_eye']),axis=0)\n",
    "                \n",
    "                right_eye = np.concatenate((right_eye, data['right_eye'][:nframes]),axis=0)\\\n",
    "                            if nframes != None else np.concatenate((right_eye, data['right_eye']),axis=0)\n",
    "                \n",
    "                headpose_pupil = np.concatenate((headpose_pupil, data['headpose_pupil'][:nframes]),axis=0)\\\n",
    "                            if nframes != None else np.concatenate((headpose_pupil, data['headpose_pupil']),axis=0)\n",
    "                    \n",
    "                face_location = np.concatenate((face_location, data['face_location'][:nframes]),axis=0)\\\n",
    "                            if nframes != None else np.concatenate((face_location, data['face_location']),axis=0)\n",
    "        else:\n",
    "            #print(\"Absent --> \",driver, seq)\n",
    "            pass\n",
    "    return left_eye, right_eye, headpose_pupil, face_location, gaze_point\n",
    "\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n",
    "\n",
    "def histogram_equalization(img):\n",
    "    gray = rgb2gray(img) \n",
    "    img_int8 = gray.astype(np.uint8)\n",
    "    return cv2.equalizeHist(img_int8)\n",
    "\n",
    "def turker_gaze(data):\n",
    "    output = np.zeros((data.shape[0], 36,60))\n",
    "    for i in range(len(data)):\n",
    "        output[i] = histogram_equalization(data[i])\n",
    "    return output\n",
    "\n",
    "\n",
    "def dataset(driver_data, drivers, sequences, nframes = None):\n",
    "    dgaze_data = {}\n",
    "    dgaze_left_eye = None\n",
    "    dgaze_right_eye = None\n",
    "    dgaze_headpose_pupil = None\n",
    "    dgaze_face_location = None\n",
    "    dgaze_gaze_point = None\n",
    "\n",
    "    for driver in tqdm((drivers), position=0, leave=True):\n",
    "        left_eye, right_eye, headpose_pupil, face_location, gaze_point = load_data(driver_data, driver, sequences, nframes = nframes)\n",
    "        \n",
    "        if dgaze_left_eye is None:\n",
    "            dgaze_left_eye = left_eye\n",
    "            dgaze_right_eye = right_eye\n",
    "            dgaze_headpose_pupil = headpose_pupil\n",
    "            dgaze_face_location = face_location\n",
    "            dgaze_gaze_point = gaze_point\n",
    "        else:\n",
    "            dgaze_left_eye = np.concatenate((dgaze_left_eye, left_eye),axis=0)\n",
    "            dgaze_right_eye = np.concatenate((dgaze_right_eye, right_eye),axis=0)\n",
    "            dgaze_headpose_pupil = np.concatenate((dgaze_headpose_pupil, headpose_pupil),axis=0)\n",
    "            dgaze_face_location = np.concatenate((dgaze_face_location, face_location),axis=0)\n",
    "            dgaze_gaze_point = np.concatenate((dgaze_gaze_point, gaze_point),axis=0)\n",
    "            \n",
    "     \n",
    "#     index = (np.where(dgaze_gaze_point[:,1]<1080) and np.where(dgaze_gaze_point[:,1]>=0) and \\\n",
    "#                np.where(dgaze_gaze_point[:,0]<1920) and np.where(dgaze_gaze_point[:,0]>=0))[0]\n",
    "    \n",
    "#     print(len(index))\n",
    "#     print(index)\n",
    "\n",
    "    x1 = (dgaze_gaze_point[:,0]<1920) & (dgaze_gaze_point[:,0]>=0)\n",
    "    x2 = (dgaze_gaze_point[:,1]<1080) & (dgaze_gaze_point[:,1]>=0)\n",
    "    index = x1&x2\n",
    "\n",
    "    dgaze_data['left_eye'] = (dgaze_left_eye[index]).astype(np.float32)\n",
    "    dgaze_data['right_eye'] = (dgaze_right_eye[index]).astype(np.float32)\n",
    "    dgaze_data['headpose_pupil'] = dgaze_headpose_pupil[index].astype(np.float32)\n",
    "    dgaze_data['face_location'] = dgaze_face_location[index].astype(np.float32)\n",
    "    dgaze_data['face_features'] = np.concatenate((dgaze_headpose_pupil[:,[1,2,3,4,5,6,7,8,9,10]],dgaze_face_location[:]), axis =1)[index].astype(np.float32)\n",
    "    dgaze_data['gaze_point'] = dgaze_gaze_point[index].astype(np.float32)\n",
    "    \n",
    "    return dgaze_data\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a100",
   "language": "python",
   "name": "a100"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
